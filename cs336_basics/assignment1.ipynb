{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e72cbc8",
   "metadata": {},
   "source": [
    "step 1: add the special token to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31cd3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "special_token = \"<|endoftext|>\"\n",
    "vocab.update({special_token: 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45605594",
   "metadata": {},
   "source": [
    "step 2: add 256 byte values to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3498114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(256):\n",
    "    char = chr(i)\n",
    "    vocab.update({char: i + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "839c2484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|endoftext|>': 0,\n",
       " '\\x00': 1,\n",
       " '\\x01': 2,\n",
       " '\\x02': 3,\n",
       " '\\x03': 4,\n",
       " '\\x04': 5,\n",
       " '\\x05': 6,\n",
       " '\\x06': 7,\n",
       " '\\x07': 8,\n",
       " '\\x08': 9,\n",
       " '\\t': 10,\n",
       " '\\n': 11,\n",
       " '\\x0b': 12,\n",
       " '\\x0c': 13,\n",
       " '\\r': 14,\n",
       " '\\x0e': 15,\n",
       " '\\x0f': 16,\n",
       " '\\x10': 17,\n",
       " '\\x11': 18,\n",
       " '\\x12': 19,\n",
       " '\\x13': 20,\n",
       " '\\x14': 21,\n",
       " '\\x15': 22,\n",
       " '\\x16': 23,\n",
       " '\\x17': 24,\n",
       " '\\x18': 25,\n",
       " '\\x19': 26,\n",
       " '\\x1a': 27,\n",
       " '\\x1b': 28,\n",
       " '\\x1c': 29,\n",
       " '\\x1d': 30,\n",
       " '\\x1e': 31,\n",
       " '\\x1f': 32,\n",
       " ' ': 33,\n",
       " '!': 34,\n",
       " '\"': 35,\n",
       " '#': 36,\n",
       " '$': 37,\n",
       " '%': 38,\n",
       " '&': 39,\n",
       " \"'\": 40,\n",
       " '(': 41,\n",
       " ')': 42,\n",
       " '*': 43,\n",
       " '+': 44,\n",
       " ',': 45,\n",
       " '-': 46,\n",
       " '.': 47,\n",
       " '/': 48,\n",
       " '0': 49,\n",
       " '1': 50,\n",
       " '2': 51,\n",
       " '3': 52,\n",
       " '4': 53,\n",
       " '5': 54,\n",
       " '6': 55,\n",
       " '7': 56,\n",
       " '8': 57,\n",
       " '9': 58,\n",
       " ':': 59,\n",
       " ';': 60,\n",
       " '<': 61,\n",
       " '=': 62,\n",
       " '>': 63,\n",
       " '?': 64,\n",
       " '@': 65,\n",
       " 'A': 66,\n",
       " 'B': 67,\n",
       " 'C': 68,\n",
       " 'D': 69,\n",
       " 'E': 70,\n",
       " 'F': 71,\n",
       " 'G': 72,\n",
       " 'H': 73,\n",
       " 'I': 74,\n",
       " 'J': 75,\n",
       " 'K': 76,\n",
       " 'L': 77,\n",
       " 'M': 78,\n",
       " 'N': 79,\n",
       " 'O': 80,\n",
       " 'P': 81,\n",
       " 'Q': 82,\n",
       " 'R': 83,\n",
       " 'S': 84,\n",
       " 'T': 85,\n",
       " 'U': 86,\n",
       " 'V': 87,\n",
       " 'W': 88,\n",
       " 'X': 89,\n",
       " 'Y': 90,\n",
       " 'Z': 91,\n",
       " '[': 92,\n",
       " '\\\\': 93,\n",
       " ']': 94,\n",
       " '^': 95,\n",
       " '_': 96,\n",
       " '`': 97,\n",
       " 'a': 98,\n",
       " 'b': 99,\n",
       " 'c': 100,\n",
       " 'd': 101,\n",
       " 'e': 102,\n",
       " 'f': 103,\n",
       " 'g': 104,\n",
       " 'h': 105,\n",
       " 'i': 106,\n",
       " 'j': 107,\n",
       " 'k': 108,\n",
       " 'l': 109,\n",
       " 'm': 110,\n",
       " 'n': 111,\n",
       " 'o': 112,\n",
       " 'p': 113,\n",
       " 'q': 114,\n",
       " 'r': 115,\n",
       " 's': 116,\n",
       " 't': 117,\n",
       " 'u': 118,\n",
       " 'v': 119,\n",
       " 'w': 120,\n",
       " 'x': 121,\n",
       " 'y': 122,\n",
       " 'z': 123,\n",
       " '{': 124,\n",
       " '|': 125,\n",
       " '}': 126,\n",
       " '~': 127,\n",
       " '\\x7f': 128,\n",
       " '\\x80': 129,\n",
       " '\\x81': 130,\n",
       " '\\x82': 131,\n",
       " '\\x83': 132,\n",
       " '\\x84': 133,\n",
       " '\\x85': 134,\n",
       " '\\x86': 135,\n",
       " '\\x87': 136,\n",
       " '\\x88': 137,\n",
       " '\\x89': 138,\n",
       " '\\x8a': 139,\n",
       " '\\x8b': 140,\n",
       " '\\x8c': 141,\n",
       " '\\x8d': 142,\n",
       " '\\x8e': 143,\n",
       " '\\x8f': 144,\n",
       " '\\x90': 145,\n",
       " '\\x91': 146,\n",
       " '\\x92': 147,\n",
       " '\\x93': 148,\n",
       " '\\x94': 149,\n",
       " '\\x95': 150,\n",
       " '\\x96': 151,\n",
       " '\\x97': 152,\n",
       " '\\x98': 153,\n",
       " '\\x99': 154,\n",
       " '\\x9a': 155,\n",
       " '\\x9b': 156,\n",
       " '\\x9c': 157,\n",
       " '\\x9d': 158,\n",
       " '\\x9e': 159,\n",
       " '\\x9f': 160,\n",
       " '\\xa0': 161,\n",
       " '¡': 162,\n",
       " '¢': 163,\n",
       " '£': 164,\n",
       " '¤': 165,\n",
       " '¥': 166,\n",
       " '¦': 167,\n",
       " '§': 168,\n",
       " '¨': 169,\n",
       " '©': 170,\n",
       " 'ª': 171,\n",
       " '«': 172,\n",
       " '¬': 173,\n",
       " '\\xad': 174,\n",
       " '®': 175,\n",
       " '¯': 176,\n",
       " '°': 177,\n",
       " '±': 178,\n",
       " '²': 179,\n",
       " '³': 180,\n",
       " '´': 181,\n",
       " 'µ': 182,\n",
       " '¶': 183,\n",
       " '·': 184,\n",
       " '¸': 185,\n",
       " '¹': 186,\n",
       " 'º': 187,\n",
       " '»': 188,\n",
       " '¼': 189,\n",
       " '½': 190,\n",
       " '¾': 191,\n",
       " '¿': 192,\n",
       " 'À': 193,\n",
       " 'Á': 194,\n",
       " 'Â': 195,\n",
       " 'Ã': 196,\n",
       " 'Ä': 197,\n",
       " 'Å': 198,\n",
       " 'Æ': 199,\n",
       " 'Ç': 200,\n",
       " 'È': 201,\n",
       " 'É': 202,\n",
       " 'Ê': 203,\n",
       " 'Ë': 204,\n",
       " 'Ì': 205,\n",
       " 'Í': 206,\n",
       " 'Î': 207,\n",
       " 'Ï': 208,\n",
       " 'Ð': 209,\n",
       " 'Ñ': 210,\n",
       " 'Ò': 211,\n",
       " 'Ó': 212,\n",
       " 'Ô': 213,\n",
       " 'Õ': 214,\n",
       " 'Ö': 215,\n",
       " '×': 216,\n",
       " 'Ø': 217,\n",
       " 'Ù': 218,\n",
       " 'Ú': 219,\n",
       " 'Û': 220,\n",
       " 'Ü': 221,\n",
       " 'Ý': 222,\n",
       " 'Þ': 223,\n",
       " 'ß': 224,\n",
       " 'à': 225,\n",
       " 'á': 226,\n",
       " 'â': 227,\n",
       " 'ã': 228,\n",
       " 'ä': 229,\n",
       " 'å': 230,\n",
       " 'æ': 231,\n",
       " 'ç': 232,\n",
       " 'è': 233,\n",
       " 'é': 234,\n",
       " 'ê': 235,\n",
       " 'ë': 236,\n",
       " 'ì': 237,\n",
       " 'í': 238,\n",
       " 'î': 239,\n",
       " 'ï': 240,\n",
       " 'ð': 241,\n",
       " 'ñ': 242,\n",
       " 'ò': 243,\n",
       " 'ó': 244,\n",
       " 'ô': 245,\n",
       " 'õ': 246,\n",
       " 'ö': 247,\n",
       " '÷': 248,\n",
       " 'ø': 249,\n",
       " 'ù': 250,\n",
       " 'ú': 251,\n",
       " 'û': 252,\n",
       " 'ü': 253,\n",
       " 'ý': 254,\n",
       " 'þ': 255,\n",
       " 'ÿ': 256}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf40a9",
   "metadata": {},
   "source": [
    "step 3: pretokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bed9cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low', 'low', 'low', 'low', 'low', 'lower', 'lower', 'widest', 'widest', 'widest', 'newest', 'newest', 'newest', 'newest', 'newest', 'newest']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('l', 'o', 'w'): 5,\n",
       " ('l', 'o', 'w', 'e', 'r'): 2,\n",
       " ('w', 'i', 'd', 'e', 's', 't'): 3,\n",
       " ('n', 'e', 'w', 'e', 's', 't'): 6}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"low low low low low\n",
    "lower lower widest widest widest\n",
    "newest newest newest newest newest newest\"\"\"\n",
    "\n",
    "\n",
    "words = text.split()\n",
    "print(words)\n",
    "from collections import Counter\n",
    "word_counts = Counter(words)\n",
    "frequency_table = dict(word_counts)\n",
    "\n",
    "frequency_table = {tuple(word): count for word, count in frequency_table.items()}\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc272147",
   "metadata": {},
   "source": [
    "step4: merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2c47bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('l', 'o'): 7,\n",
       " ('o', 'w'): 7,\n",
       " ('w', 'e'): 8,\n",
       " ('e', 'r'): 2,\n",
       " ('w', 'i'): 3,\n",
       " ('i', 'd'): 3,\n",
       " ('d', 'e'): 3,\n",
       " ('e', 's'): 9,\n",
       " ('s', 't'): 9,\n",
       " ('n', 'e'): 6,\n",
       " ('e', 'w'): 6}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  count the frequency of all adjacent character pairs\n",
    "\n",
    "merge_tables = {}\n",
    "for word, count in frequency_table.items():\n",
    "   \n",
    "    for i in range(len(word)-1):\n",
    "     \n",
    "        char_pair = word[i:i+2]\n",
    "        if char_pair not in merge_tables:\n",
    "            merge_tables[char_pair] = count\n",
    "        else:\n",
    "            merge_tables[char_pair] += count\n",
    "    \n",
    "merge_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "461b35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('e', 's') with count: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('l', 'o', 'w'): 5,\n",
       " ('l', 'o', 'w', 'e', 'r'): 2,\n",
       " ('w', 'i', 'd', 'es', 't'): 3,\n",
       " ('n', 'e', 'w', 'es', 't'): 6}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the most frequent pair\n",
    "most_frequent_pair = max(merge_tables, key=merge_tables.get)\n",
    "print(\"Most frequent pair:\", most_frequent_pair, \"with count:\", merge_tables[most_frequent_pair])\n",
    "\n",
    "# update the frequency table by merging the most frequent pair\n",
    "new_frequency_table = {}\n",
    "for word, count in frequency_table.items():\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and word[i:i+2] == most_frequent_pair:\n",
    "            new_word.append(''.join(most_frequent_pair))\n",
    "            i += 2\n",
    "        else:\n",
    "            new_word.append(word[i])\n",
    "            i += 1\n",
    "    new_frequency_table[tuple(new_word)] = count\n",
    "\n",
    "\n",
    "new_frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd21ad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('l', 'o'): 7,\n",
       " ('o', 'w'): 7,\n",
       " ('w', 'e'): 2,\n",
       " ('e', 'r'): 2,\n",
       " ('w', 'i'): 3,\n",
       " ('i', 'd'): 3,\n",
       " ('d', 'es'): 3,\n",
       " ('es', 't'): 9,\n",
       " ('n', 'e'): 6,\n",
       " ('e', 'w'): 6,\n",
       " ('w', 'es'): 6}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  count the frequency of all adjacent character pairs\n",
    "merge_tables = {}\n",
    "for word, count in new_frequency_table.items():\n",
    "    \n",
    "     for i in range(len(word)-1):\n",
    "      \n",
    "          char_pair = word[i:i+2]\n",
    "          if char_pair not in merge_tables:\n",
    "                merge_tables[char_pair] = count\n",
    "          else:\n",
    "                merge_tables[char_pair] += count\n",
    "\n",
    "merge_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "265469dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('es', 't') with count: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('l', 'o', 'w'): 5,\n",
       " ('l', 'o', 'w', 'e', 'r'): 2,\n",
       " ('w', 'i', 'd', 'est'): 3,\n",
       " ('n', 'e', 'w', 'est'): 6}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the most frequent pair\n",
    "most_frequent_pair = max(merge_tables, key=merge_tables.get)\n",
    "print(\"Most frequent pair:\", most_frequent_pair, \"with count:\", merge_tables[most_frequent_pair])\n",
    "\n",
    "# update the frequency table by merging the most frequent pair\n",
    "frequency_table = {}\n",
    "for word, count in new_frequency_table.items():\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and word[i:i+2] == most_frequent_pair:\n",
    "            new_word.append(''.join(most_frequent_pair))\n",
    "            i += 2\n",
    "        else:\n",
    "            new_word.append(word[i])\n",
    "            i += 1\n",
    "    frequency_table[tuple(new_word)] = count\n",
    "\n",
    "\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1010867",
   "metadata": {},
   "source": [
    "将merge这个过程写成loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9691e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(merge_counts):\n",
    "    current_count = 1\n",
    "    while current_count <= merge_counts:\n",
    "        print(\"\\nMerge iteration:\", current_count)\n",
    "        #  count the frequency of all adjacent character pairs\n",
    "        merge_tables = {}\n",
    "        for word, count in frequency_table.items():\n",
    "            \n",
    "             for i in range(len(word)-1):\n",
    "              \n",
    "                  char_pair = word[i:i+2]\n",
    "                  if char_pair not in merge_tables:\n",
    "                        merge_tables[char_pair] = count\n",
    "                  else:\n",
    "                        merge_tables[char_pair] += count\n",
    "\n",
    "        # merge the most frequent pair\n",
    "        most_frequent_pair = max(merge_tables, key=merge_tables.get)\n",
    "        print(\"Most frequent pair:\", most_frequent_pair, \"with count:\", merge_tables[most_frequent_pair])\n",
    "\n",
    "        # update the frequency table by merging the most frequent pair\n",
    "        new_frequency_table = {}\n",
    "        for word, count in frequency_table.items():\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                if i < len(word) - 1 and word[i:i+2] == most_frequent_pair:\n",
    "                    new_word.append(''.join(most_frequent_pair))\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_frequency_table[tuple(new_word)] = count\n",
    "\n",
    "        frequency_table.clear()\n",
    "        frequency_table.update(new_frequency_table)\n",
    "        current_count += 1 \n",
    "\n",
    "    return frequency_table, merge_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67e683e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merge iteration: 1\n",
      "Most frequent pair: ('lo', 'w') with count: 7\n",
      "\n",
      "Merge iteration: 2\n",
      "Most frequent pair: ('n', 'e') with count: 6\n",
      "\n",
      "Merge iteration: 3\n",
      "Most frequent pair: ('ne', 'w') with count: 6\n",
      "\n",
      "Merge iteration: 4\n",
      "Most frequent pair: ('new', 'est') with count: 6\n",
      "\n",
      "Merge iteration: 5\n",
      "Most frequent pair: ('w', 'i') with count: 3\n"
     ]
    }
   ],
   "source": [
    "frequency_table, merge_tables = merge(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6e3152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('low', 'e'): 2, ('e', 'r'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a26b500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('low',): 5, ('low', 'e', 'r'): 2, ('wi', 'd', 'est'): 3, ('newest',): 6}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442e7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_finetune3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
