{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b7719d",
   "metadata": {},
   "source": [
    "# ÂØπÊ¶ÇÂøµÁöÑÁêÜËß£Âíå‰∏æ‰æã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5a0ad",
   "metadata": {},
   "source": [
    "\n",
    "### Character (Â≠óÁ¨¶)\n",
    "- **ÂÆö‰πâ**: ‰∫∫Á±ªÂèØËØªÁöÑÊñáÊú¨Âçï‰Ωç\n",
    "- **Á§∫‰æã**: `'h'`, `'e'`, `'‰∏≠'`, `'Êñá'`, `'üòÄ'`\n",
    "- **Python Á±ªÂûã**: `str`\n",
    "- **ÁâπÁÇπ**: \n",
    "  - Unicode Â≠óÁ¨¶Êï∞ÈáèÂ∑®Â§ß (Ë∂ÖËøá 100 ‰∏áÁßç)\n",
    "  - ‰∏çÂêåÂ≠óÁ¨¶ÁöÑ Unicode Á†ÅÁÇπ‰∏çÂêå\n",
    "  - Â≠óÁ¨¶Êï∞ ‚â† Â≠óËäÇÊï∞\n",
    "\n",
    "### Byte (Â≠óËäÇ)\n",
    "- **ÂÆö‰πâ**: ËÆ°ÁÆóÊú∫Â≠òÂÇ®ÁöÑÂü∫Êú¨Âçï‰Ωç\n",
    "- **ËåÉÂõ¥**: 0-255 (2^8 = 256 ÁßçÂèØËÉΩ)\n",
    "- **Python Á±ªÂûã**: `bytes`\n",
    "- **ÁâπÁÇπ**:\n",
    "  - Âõ∫ÂÆöËåÉÂõ¥: 0-255\n",
    "  - 1 Â≠óËäÇ = 8 ‰Ωç (bit)\n",
    "  - ÊâÄÊúâÊñáÊú¨ÈÉΩÂèØ‰ª•ËΩ¨Êç¢‰∏∫Â≠óËäÇÂ∫èÂàó\n",
    "\n",
    "### Unicode\n",
    "- **ÂÆö‰πâ**ÔºöÂ≠óÁ¨¶ÁºñÁ†ÅÊ†áÂáÜÔºå‰∏∫ÊØè‰∏™Â≠óÁ¨¶ÂàÜÈÖçÂîØ‰∏ÄÁöÑÁ†ÅÁÇπÔºàÊ†áÂáÜÔºâ\n",
    "- **Unicode Á†ÅÁÇπ (Code Point)**: ÊØè‰∏™Â≠óÁ¨¶ÈÉΩÊúâ‰∏Ä‰∏™ÂîØ‰∏ÄÁöÑ Unicode Á†ÅÁÇπÔºåÈÄöÂ∏∏Áî® `U+` ÂâçÁºÄË°®Á§∫ÔºàÂçÅÂÖ≠ËøõÂà∂ÔºâÔºå‰æãÂ¶Ç: `U+0068`, `U+4E2D`, `U+1F600`\n",
    "- **Á§∫‰æã**: \n",
    "```python\n",
    "ord('h')    # 104 (U+0068) \n",
    "ord('‰∏≠')   # 20013 (U+4E2D)\n",
    "```\n",
    "- **Python ÂáΩÊï∞**: ord(char)\n",
    "\n",
    "\n",
    "### UTF-8 ÁºñÁ†Å\n",
    "\n",
    "- **ÂÆö‰πâ**: Â∞Ü Unicode Á†ÅÁÇπÁºñÁ†ÅÊàêÂ≠óËäÇÂ∫èÂàóÁöÑÊñπÂºè(ËÆ°ÁÆóÊú∫ÈúÄË¶ÅÂ≠óËäÇÂ∫èÂàóÊù•Â≠òÂÇ®)\n",
    "\n",
    "\n",
    "- **Á§∫‰æã**:\n",
    "```python\n",
    "'h'.encode('utf-8')    # b'h' (1 Â≠óËäÇ)\n",
    "'‰∏≠'.encode('utf-8')   # b'\\xe4\\xb8\\xad' (3 Â≠óËäÇ)\n",
    "'üòÄ'.encode('utf-8')   # b'\\xf0\\x9f\\x98\\x80' (4 Â≠óËäÇ)\n",
    "```\n",
    "\n",
    "- **Python ÊñπÊ≥ï**: char.encode('utf-8')\n",
    "\n",
    "## Â≠óÁ¨¶‰∏éÂ≠óËäÇÁöÑÂÖ≥Á≥ª\n",
    "\n",
    "```\n",
    "Character (Â≠óÁ¨¶)\n",
    "    ‚Üì\n",
    "Unicode Á†ÅÁÇπ (Êï∞Â≠óÊ†áËØÜÁ¨¶)\n",
    "    ‚Üì\n",
    "UTF-8 ÁºñÁ†Å (Â≠óËäÇÂ∫èÂàó)\n",
    "```\n",
    "\n",
    "### Á§∫‰æã: `'‰∏≠'`\n",
    "\n",
    "```\n",
    "Â≠óÁ¨¶: '‰∏≠'\n",
    "    ‚Üì\n",
    "Unicode Á†ÅÁÇπ: 20013 (U+4E2D)\n",
    "    ‚Üì\n",
    "UTF-8 ÁºñÁ†Å: b'\\xe4\\xb8\\xad' (3 Â≠óËäÇ)\n",
    "    ‚Üì\n",
    "Â≠óËäÇÂÄº: [228, 184, 173]\n",
    "```\n",
    "\n",
    "Ê¶ÇÂøµÂÆπÊòìÊ∑∑Ê∑ÜÔºö\n",
    "- Unicode ‰∏çÊòØÂ≠óÁ¨¶ÔºåUnicode ÊòØÂ≠óÁ¨¶ÁºñÁ†ÅÊ†áÂáÜÔºå‰∏∫Â≠óÁ¨¶ÂàÜÈÖçÁ†ÅÁÇπÔºåÊòØÂ≠óÁ¨¶ÁöÑÊï∞Â≠óË°®Á§∫„ÄÇ\n",
    "- Unicode Âíå UTF-8 ‰∏çÊòØ‰∏ÄÂõû‰∫ãÔºåUnicode ÊòØÊ†áÂáÜÔºåÔºàÂÆö‰πâÂ≠óÁ¨¶ÂíåÁ†ÅÁÇπÔºâÔºåUTF-8 ÊòØÁºñÁ†ÅÊñπÂºèÔºàÂ∞ÜÁ†ÅÁÇπÁºñÁ†ÅÊàêÂ≠óËäÇÔºâ„ÄÇ\n",
    "\n",
    "\n",
    "\n",
    "### Â≠óËäÇÁ∫ßÂà´ÁöÑ‰ºòÂäø\n",
    "\n",
    "1. **ÂàùÂßãËØçÊ±áË°®Â§ßÂ∞èÂõ∫ÂÆö**\n",
    "   - Â≠óÁ¨¶Á∫ßÂà´: ÈúÄË¶ÅÂ§ÑÁêÜÊâÄÊúâ Unicode Â≠óÁ¨¶ (100‰∏á+)\n",
    "   - Â≠óËäÇÁ∫ßÂà´: Âè™ÈúÄË¶Å 256 ‰∏™ÂàùÂßã token (0-255)\n",
    "\n",
    "2. **Ë¶ÜÁõñÊÄß**\n",
    "   - Â≠óÁ¨¶Á∫ßÂà´: Êó†Ê≥ïÂ§ÑÁêÜËÆ≠ÁªÉÊó∂Êú™ËßÅËøáÁöÑÂ≠óÁ¨¶\n",
    "   - Â≠óËäÇÁ∫ßÂà´: ÂèØ‰ª•Â§ÑÁêÜ‰ªª‰Ωï Unicode Â≠óÁ¨¶\n",
    "\n",
    "3. **Áªü‰∏ÄÊÄß**\n",
    "   - Â≠óÁ¨¶Á∫ßÂà´: ‰∏çÂêåËØ≠Ë®ÄÁöÑÂ≠óÁ¨¶ÈõÜÂ∑ÆÂºÇÂæàÂ§ß\n",
    "   - Â≠óËäÇÁ∫ßÂà´: ÊâÄÊúâÊñáÊú¨ÈÉΩÂèØ‰ª•ËΩ¨Êç¢‰∏∫Â≠óËäÇÂ∫èÂàó\n",
    "\n",
    "4. **ÁÆÄÂçïÊÄß**\n",
    "   - Â≠óËäÇËåÉÂõ¥Âõ∫ÂÆö (0-255)\n",
    "   - ÂèØ‰ª•Â≠¶‰π†Â∏∏ËßÅÂ≠óËäÇÁªÑÂêàÁöÑÊ®°Âºè\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a957c",
   "metadata": {},
   "source": [
    "# ÂàÜËØçÂô®ËÆ≠ÁªÉÂá∫Áé∞ÁöÑÊ¶ÇÂøµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01466695",
   "metadata": {},
   "source": [
    "\n",
    "### 1. vocab (ËØçÊ±áË°®)\n",
    "\n",
    "**Á±ªÂûã**: `dict[int, bytes]`\n",
    "\n",
    "**Âê´‰πâ**: ‰ªé token ID (Êï¥Êï∞) Êò†Â∞ÑÂà∞ token ÁöÑÂ≠óËäÇË°®Á§∫\n",
    "\n",
    "**ÁªìÊûÑ**:\n",
    "```python\n",
    "vocab = {\n",
    "    0: b'\\x00',        # token ID 0 -> Â≠óËäÇ 0\n",
    "    1: b'\\x01',        # token ID 1 -> Â≠óËäÇ 1\n",
    "    ...\n",
    "    104: b'h',         # token ID 104 -> 'h' Â≠óËäÇ\n",
    "    256: b'he',        # token ID 256 -> 'he' (BPEÂêàÂπ∂ÂêéÁöÑtoken)\n",
    "    257: b'll',        # token ID 257 -> 'll' (BPEÂêàÂπ∂ÂêéÁöÑtoken)\n",
    "    258: b'hello',     # token ID 258 -> 'hello' (BPEÂêàÂπ∂ÂêéÁöÑtoken)\n",
    "}\n",
    "```\n",
    "\n",
    "**Â∫èÂàóÂåñÂêé** (Áî®‰∫é‰øùÂ≠òÂà∞ JSON):\n",
    "```python\n",
    "vocab_serialized = {\n",
    "    'ƒÄ': 0,           # Â≠óËäÇ 0 ÂØπÂ∫îÁöÑ unicode Â≠óÁ¨¶\n",
    "    'ƒÅ': 1,           # Â≠óËäÇ 1 ÂØπÂ∫îÁöÑ unicode Â≠óÁ¨¶\n",
    "    'ƒ†': 32,          # Á©∫Ê†ºÂ≠óËäÇÂØπÂ∫îÁöÑ unicode Â≠óÁ¨¶\n",
    "    'h': 104,         # 'h' Â≠óËäÇ\n",
    "    'he': 256,        # 'he' token\n",
    "    'll': 257,        # 'll' token\n",
    "    'hello': 258,     # 'hello' token\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. merges (ÂêàÂπ∂ËßÑÂàô)\n",
    "\n",
    "**Á±ªÂûã**: `list[tuple[bytes, bytes]]`\n",
    "\n",
    "**Âê´‰πâ**: BPEËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊåâÈ°∫Â∫èËÆ∞ÂΩïÁöÑÂêàÂπ∂Êìç‰Ωú„ÄÇÊØè‰∏™ÂÖÉÁªÑ `(token1, token2)` Ë°®Á§∫Â∞Ü `token1` Âíå `token2` ÂêàÂπ∂Êàê‰∏Ä‰∏™Êñ∞ÁöÑ token„ÄÇ\n",
    "\n",
    "**ÁªìÊûÑ**:\n",
    "```python\n",
    "merges = [\n",
    "    (b'h', b'e'),         # Á¨¨1Ê¨°ÂêàÂπ∂: h + e -> he\n",
    "    (b'l', b'l'),         # Á¨¨2Ê¨°ÂêàÂπ∂: l + l -> ll\n",
    "    (b'he', b'll'),       # Á¨¨3Ê¨°ÂêàÂπ∂: he + ll -> hell\n",
    "    (b'hell', b'o'),      # Á¨¨4Ê¨°ÂêàÂπ∂: hell + o -> hello\n",
    "]\n",
    "```\n",
    "\n",
    "**Â∫èÂàóÂåñÂêé** (Áî®‰∫é‰øùÂ≠òÂà∞ÊñáÊú¨Êñá‰ª∂):\n",
    "```python\n",
    "merges_serialized = [\n",
    "    'h e',           # Á¨¨1Ê¨°ÂêàÂπ∂\n",
    "    'l l',           # Á¨¨2Ê¨°ÂêàÂπ∂\n",
    "    'he ll',         # Á¨¨3Ê¨°ÂêàÂπ∂\n",
    "    'hell o',        # Á¨¨4Ê¨°ÂêàÂπ∂\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÂ∫èÂàóÂåñ\n",
    "Â∫èÂàóÂåñÊòØÊåá\n",
    "\n",
    "JSON ‰∏çÊîØÊåÅ `bytes` Á±ªÂûãÔºÅ\n",
    "---\n",
    "\n",
    "## üîÑ BPE ÂêàÂπ∂ËøáÁ®ãÁ§∫‰æã\n",
    "\n",
    "ÂÅáËÆæÊàë‰ª¨Ë¶ÅÂØπÂçïËØç **\"hello\"** ËøõË°å BPE tokenizationÔºö\n",
    "\n",
    "### ÂàùÂßãÁä∂ÊÄÅ\n",
    "```\n",
    "ÂéüÂßãÊñáÊú¨: \"hello\"\n",
    "UTF-8 ÁºñÁ†Å: b'hello'\n",
    "Â≠óËäÇÂÄº: [104, 101, 108, 108, 111]\n",
    "ÂàùÂßã tokens: [b'h', b'e', b'l', b'l', b'o']\n",
    "```\n",
    "\n",
    "### Â∫îÁî® merges (ÊåâÈ°∫Â∫è)\n",
    "\n",
    "**Ê≠•È™§ 1**: ÂêàÂπ∂ `b'h'` + `b'e'`\n",
    "```\n",
    "ÂêàÂπ∂Ââç: [b'h', b'e', b'l', b'l', b'o']\n",
    "ÂêàÂπ∂Âêé: [b'he', b'l', b'l', b'o']\n",
    "```\n",
    "\n",
    "**Ê≠•È™§ 2**: ÂêàÂπ∂ `b'l'` + `b'l'`\n",
    "```\n",
    "ÂêàÂπ∂Ââç: [b'he', b'l', b'l', b'o']\n",
    "ÂêàÂπ∂Âêé: [b'he', b'll', b'o']\n",
    "```\n",
    "\n",
    "**Ê≠•È™§ 3**: ÂêàÂπ∂ `b'he'` + `b'll'`\n",
    "```\n",
    "ÂêàÂπ∂Ââç: [b'he', b'll', b'o']\n",
    "ÂêàÂπ∂Âêé: [b'hell', b'o']\n",
    "```\n",
    "\n",
    "**Ê≠•È™§ 4**: ÂêàÂπ∂ `b'hell'` + `b'o'`\n",
    "```\n",
    "ÂêàÂπ∂Ââç: [b'hell', b'o']\n",
    "ÂêàÂπ∂Âêé: [b'hello']\n",
    "```\n",
    "\n",
    "### ÊúÄÁªàÁªìÊûú\n",
    "```\n",
    "ÊúÄÁªà tokens: [b'hello']\n",
    "ÊúÄÁªà token ID: 258 (ÂÅáËÆæ vocab[258] = b'hello')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ Êñá‰ª∂‰øùÂ≠òÊ†ºÂºè\n",
    "\n",
    "### vocab.json\n",
    "```json\n",
    "{\n",
    "  \"ƒÄ\": 0,\n",
    "  \"ƒÅ\": 1,\n",
    "  \"ƒ†\": 32,\n",
    "  \"h\": 104,\n",
    "  \"he\": 256,\n",
    "  \"ll\": 257,\n",
    "  \"hello\": 258\n",
    "}\n",
    "```\n",
    "\n",
    "### merges.txt\n",
    "```\n",
    "h e\n",
    "l l\n",
    "he ll\n",
    "hell o\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d41dbc1",
   "metadata": {},
   "source": [
    "# merge ÈáåÈù¢ÁöÑpre_token_countsÂíå merge_tables \n",
    "## ÂàùÂßãÁä∂ÊÄÅ\n",
    "```python\n",
    "pre_token_counts = { (b'h', b'e', b'l', b'l', b'o'): 2,  # \"hello\" Âá∫Áé∞2Ê¨°   \n",
    "(b'w', b'o', b'r', b'l', b'd'): 1,  #\"world\" Âá∫Áé∞1Ê¨°\n",
    "}\n",
    "merge_tables = {    (b'h', b'e'): 2,  # h-e Âá∫Áé∞2Ê¨°    \n",
    "(b'e', b'l'): 2,  # e-l Âá∫Áé∞2Ê¨°    \n",
    "(b'l', b'l'): 2,  # l-l Âá∫Áé∞2Ê¨° ‚Üê ÊúÄÈ´òÈ¢ëÔºÅ    \n",
    "(b'l', b'o'): 2,  # l-o Âá∫Áé∞2Ê¨°    \n",
    "(b'w', b'o'): 1,  # w-o Âá∫Áé∞1Ê¨°    \n",
    "(b'o', b'r'): 1,  # o-r Âá∫Áé∞1Ê¨°    \n",
    "(b'r', b'l'): 1,  # r-l Âá∫Áé∞1Ê¨°    \n",
    "(b'l', b'd'): 1,  # l-d Âá∫Áé∞1Ê¨°}\n",
    "```\n",
    "\n",
    "## Á¨¨1Ê≠•ÔºöÊâæÂà∞ÊúÄÈ´òÈ¢ë pair\n",
    "(b'l', b'l') È¢ëÁéáÊúÄÈ´òÔºåÂêàÂπ∂‰∏∫ b'll'\n",
    "Á¨¨2Ê≠•ÔºöÂÖàÊõ¥Êñ∞ pre_token_counts\n",
    "\n",
    "## Á¨¨‰∫åÊ≠•ÔºöÂÖàÊõ¥Êñ∞ pre_token_counts\n",
    "```python\n",
    "# Êõ¥Êñ∞Ââç\n",
    "pre_token_counts = { (b'h', b'e', b'l', b'l', b'o'): 2,   \n",
    " (b'w', b'o', b'r', b'l', b'd'): 1,} \n",
    " \n",
    " \n",
    " # Êõ¥Êñ∞ÂêéÔºàÂ∞Ü l-l ÊõøÊç¢‰∏∫ llÔºâ\n",
    " pre_token_counts = {(b'h', b'e', b'll', b'o'): 2,   # hello ‚Üí he + ll + o    \n",
    " (b'w', b'o', b'r', b'l', b'd'): 1, #world ‰∏≠Ê≤°Êúâ l-lÔºå‰∏çÂèò\n",
    " }\n",
    "```\n",
    "## Á¨¨3Ê≠•ÔºöÂü∫‰∫éÊñ∞ÁöÑ pre_token_counts Êõ¥Êñ∞ merge_tables\n",
    "\n",
    "```python\n",
    "\n",
    "merge_tables = {\n",
    "(b'h', b'e'): 2, # h-e ‰ªçÁÑ∂2Ê¨°    \n",
    "(b'e', b'll'): 2, # e-ll Âá∫Áé∞2Ê¨°ÔºàÊñ∞Â¢ûÔºâ\n",
    "(b'll', b'o'): 2,  # ll-o Âá∫Áé∞2Ê¨°ÔºàÊñ∞Â¢ûÔºâ    \n",
    "(b'w', b'o'): 1,      # w-o ‰ªçÁÑ∂1Ê¨°  \n",
    "(b'o', b'r'): 1,      # o-r ‰ªçÁÑ∂1Ê¨°  \n",
    "(b'r', b'l'): 1,      # r-l ‰ªçÁÑ∂1Ê¨°  \n",
    "(b'l', b'd'): 1,      # l-d ‰ªçÁÑ∂1Ê¨°    \n",
    "#(b'l', b'l') Â∑≤Áªè‰∏çÂ≠òÂú®‰∫Ü \n",
    "\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f79e5",
   "metadata": {},
   "source": [
    "# Profile ÈÉ®ÂàÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e72cbc8",
   "metadata": {},
   "source": [
    "step 1: add the special token to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31cd3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "special_token = \"<|endoftext|>\"\n",
    "vocab.update({special_token: 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45605594",
   "metadata": {},
   "source": [
    "step 2: add 256 byte values to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3498114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(256):\n",
    "    char = chr(i)\n",
    "    vocab.update({char: i + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "839c2484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|endoftext|>': 0,\n",
       " '\\x00': 1,\n",
       " '\\x01': 2,\n",
       " '\\x02': 3,\n",
       " '\\x03': 4,\n",
       " '\\x04': 5,\n",
       " '\\x05': 6,\n",
       " '\\x06': 7,\n",
       " '\\x07': 8,\n",
       " '\\x08': 9,\n",
       " '\\t': 10,\n",
       " '\\n': 11,\n",
       " '\\x0b': 12,\n",
       " '\\x0c': 13,\n",
       " '\\r': 14,\n",
       " '\\x0e': 15,\n",
       " '\\x0f': 16,\n",
       " '\\x10': 17,\n",
       " '\\x11': 18,\n",
       " '\\x12': 19,\n",
       " '\\x13': 20,\n",
       " '\\x14': 21,\n",
       " '\\x15': 22,\n",
       " '\\x16': 23,\n",
       " '\\x17': 24,\n",
       " '\\x18': 25,\n",
       " '\\x19': 26,\n",
       " '\\x1a': 27,\n",
       " '\\x1b': 28,\n",
       " '\\x1c': 29,\n",
       " '\\x1d': 30,\n",
       " '\\x1e': 31,\n",
       " '\\x1f': 32,\n",
       " ' ': 33,\n",
       " '!': 34,\n",
       " '\"': 35,\n",
       " '#': 36,\n",
       " '$': 37,\n",
       " '%': 38,\n",
       " '&': 39,\n",
       " \"'\": 40,\n",
       " '(': 41,\n",
       " ')': 42,\n",
       " '*': 43,\n",
       " '+': 44,\n",
       " ',': 45,\n",
       " '-': 46,\n",
       " '.': 47,\n",
       " '/': 48,\n",
       " '0': 49,\n",
       " '1': 50,\n",
       " '2': 51,\n",
       " '3': 52,\n",
       " '4': 53,\n",
       " '5': 54,\n",
       " '6': 55,\n",
       " '7': 56,\n",
       " '8': 57,\n",
       " '9': 58,\n",
       " ':': 59,\n",
       " ';': 60,\n",
       " '<': 61,\n",
       " '=': 62,\n",
       " '>': 63,\n",
       " '?': 64,\n",
       " '@': 65,\n",
       " 'A': 66,\n",
       " 'B': 67,\n",
       " 'C': 68,\n",
       " 'D': 69,\n",
       " 'E': 70,\n",
       " 'F': 71,\n",
       " 'G': 72,\n",
       " 'H': 73,\n",
       " 'I': 74,\n",
       " 'J': 75,\n",
       " 'K': 76,\n",
       " 'L': 77,\n",
       " 'M': 78,\n",
       " 'N': 79,\n",
       " 'O': 80,\n",
       " 'P': 81,\n",
       " 'Q': 82,\n",
       " 'R': 83,\n",
       " 'S': 84,\n",
       " 'T': 85,\n",
       " 'U': 86,\n",
       " 'V': 87,\n",
       " 'W': 88,\n",
       " 'X': 89,\n",
       " 'Y': 90,\n",
       " 'Z': 91,\n",
       " '[': 92,\n",
       " '\\\\': 93,\n",
       " ']': 94,\n",
       " '^': 95,\n",
       " '_': 96,\n",
       " '`': 97,\n",
       " 'a': 98,\n",
       " 'b': 99,\n",
       " 'c': 100,\n",
       " 'd': 101,\n",
       " 'e': 102,\n",
       " 'f': 103,\n",
       " 'g': 104,\n",
       " 'h': 105,\n",
       " 'i': 106,\n",
       " 'j': 107,\n",
       " 'k': 108,\n",
       " 'l': 109,\n",
       " 'm': 110,\n",
       " 'n': 111,\n",
       " 'o': 112,\n",
       " 'p': 113,\n",
       " 'q': 114,\n",
       " 'r': 115,\n",
       " 's': 116,\n",
       " 't': 117,\n",
       " 'u': 118,\n",
       " 'v': 119,\n",
       " 'w': 120,\n",
       " 'x': 121,\n",
       " 'y': 122,\n",
       " 'z': 123,\n",
       " '{': 124,\n",
       " '|': 125,\n",
       " '}': 126,\n",
       " '~': 127,\n",
       " '\\x7f': 128,\n",
       " '\\x80': 129,\n",
       " '\\x81': 130,\n",
       " '\\x82': 131,\n",
       " '\\x83': 132,\n",
       " '\\x84': 133,\n",
       " '\\x85': 134,\n",
       " '\\x86': 135,\n",
       " '\\x87': 136,\n",
       " '\\x88': 137,\n",
       " '\\x89': 138,\n",
       " '\\x8a': 139,\n",
       " '\\x8b': 140,\n",
       " '\\x8c': 141,\n",
       " '\\x8d': 142,\n",
       " '\\x8e': 143,\n",
       " '\\x8f': 144,\n",
       " '\\x90': 145,\n",
       " '\\x91': 146,\n",
       " '\\x92': 147,\n",
       " '\\x93': 148,\n",
       " '\\x94': 149,\n",
       " '\\x95': 150,\n",
       " '\\x96': 151,\n",
       " '\\x97': 152,\n",
       " '\\x98': 153,\n",
       " '\\x99': 154,\n",
       " '\\x9a': 155,\n",
       " '\\x9b': 156,\n",
       " '\\x9c': 157,\n",
       " '\\x9d': 158,\n",
       " '\\x9e': 159,\n",
       " '\\x9f': 160,\n",
       " '\\xa0': 161,\n",
       " '¬°': 162,\n",
       " '¬¢': 163,\n",
       " '¬£': 164,\n",
       " '¬§': 165,\n",
       " '¬•': 166,\n",
       " '¬¶': 167,\n",
       " '¬ß': 168,\n",
       " '¬®': 169,\n",
       " '¬©': 170,\n",
       " '¬™': 171,\n",
       " '¬´': 172,\n",
       " '¬¨': 173,\n",
       " '\\xad': 174,\n",
       " '¬Æ': 175,\n",
       " '¬Ø': 176,\n",
       " '¬∞': 177,\n",
       " '¬±': 178,\n",
       " '¬≤': 179,\n",
       " '¬≥': 180,\n",
       " '¬¥': 181,\n",
       " '¬µ': 182,\n",
       " '¬∂': 183,\n",
       " '¬∑': 184,\n",
       " '¬∏': 185,\n",
       " '¬π': 186,\n",
       " '¬∫': 187,\n",
       " '¬ª': 188,\n",
       " '¬º': 189,\n",
       " '¬Ω': 190,\n",
       " '¬æ': 191,\n",
       " '¬ø': 192,\n",
       " '√Ä': 193,\n",
       " '√Å': 194,\n",
       " '√Ç': 195,\n",
       " '√É': 196,\n",
       " '√Ñ': 197,\n",
       " '√Ö': 198,\n",
       " '√Ü': 199,\n",
       " '√á': 200,\n",
       " '√à': 201,\n",
       " '√â': 202,\n",
       " '√ä': 203,\n",
       " '√ã': 204,\n",
       " '√å': 205,\n",
       " '√ç': 206,\n",
       " '√é': 207,\n",
       " '√è': 208,\n",
       " '√ê': 209,\n",
       " '√ë': 210,\n",
       " '√í': 211,\n",
       " '√ì': 212,\n",
       " '√î': 213,\n",
       " '√ï': 214,\n",
       " '√ñ': 215,\n",
       " '√ó': 216,\n",
       " '√ò': 217,\n",
       " '√ô': 218,\n",
       " '√ö': 219,\n",
       " '√õ': 220,\n",
       " '√ú': 221,\n",
       " '√ù': 222,\n",
       " '√û': 223,\n",
       " '√ü': 224,\n",
       " '√†': 225,\n",
       " '√°': 226,\n",
       " '√¢': 227,\n",
       " '√£': 228,\n",
       " '√§': 229,\n",
       " '√•': 230,\n",
       " '√¶': 231,\n",
       " '√ß': 232,\n",
       " '√®': 233,\n",
       " '√©': 234,\n",
       " '√™': 235,\n",
       " '√´': 236,\n",
       " '√¨': 237,\n",
       " '√≠': 238,\n",
       " '√Æ': 239,\n",
       " '√Ø': 240,\n",
       " '√∞': 241,\n",
       " '√±': 242,\n",
       " '√≤': 243,\n",
       " '√≥': 244,\n",
       " '√¥': 245,\n",
       " '√µ': 246,\n",
       " '√∂': 247,\n",
       " '√∑': 248,\n",
       " '√∏': 249,\n",
       " '√π': 250,\n",
       " '√∫': 251,\n",
       " '√ª': 252,\n",
       " '√º': 253,\n",
       " '√Ω': 254,\n",
       " '√æ': 255,\n",
       " '√ø': 256}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf40a9",
   "metadata": {},
   "source": [
    "step 3: pretokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bed9cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low', 'low', 'low', 'low', 'low', 'lower', 'lower', 'widest', 'widest', 'widest', 'newest', 'newest', 'newest', 'newest', 'newest', 'newest']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('l', 'o', 'w'): 5,\n",
       " ('l', 'o', 'w', 'e', 'r'): 2,\n",
       " ('w', 'i', 'd', 'e', 's', 't'): 3,\n",
       " ('n', 'e', 'w', 'e', 's', 't'): 6}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"low low low low low\n",
    "lower lower widest widest widest\n",
    "newest newest newest newest newest newest\"\"\"\n",
    "\n",
    "\n",
    "words = text.split()\n",
    "print(words)\n",
    "from collections import Counter\n",
    "word_counts = Counter(words)\n",
    "frequency_table = dict(word_counts)\n",
    "\n",
    "frequency_table = {tuple(word): count for word, count in frequency_table.items()}\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc272147",
   "metadata": {},
   "source": [
    "step4: merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2c47bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('l', 'o'): 7,\n",
       " ('o', 'w'): 7,\n",
       " ('w', 'e'): 8,\n",
       " ('e', 'r'): 2,\n",
       " ('w', 'i'): 3,\n",
       " ('i', 'd'): 3,\n",
       " ('d', 'e'): 3,\n",
       " ('e', 's'): 9,\n",
       " ('s', 't'): 9,\n",
       " ('n', 'e'): 6,\n",
       " ('e', 'w'): 6}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  count the frequency of all adjacent character pairs\n",
    "\n",
    "merge_tables = {}\n",
    "for word, count in frequency_table.items():\n",
    "   \n",
    "    for i in range(len(word)-1):\n",
    "     \n",
    "        char_pair = word[i:i+2]\n",
    "        if char_pair not in merge_tables:\n",
    "            merge_tables[char_pair] = count\n",
    "        else:\n",
    "            merge_tables[char_pair] += count\n",
    "    \n",
    "merge_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "461b35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('e', 's') with count: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('l', 'o', 'w'): 5,\n",
       " ('l', 'o', 'w', 'e', 'r'): 2,\n",
       " ('w', 'i', 'd', 'es', 't'): 3,\n",
       " ('n', 'e', 'w', 'es', 't'): 6}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the most frequent pair\n",
    "most_frequent_pair = max(merge_tables, key=merge_tables.get)\n",
    "print(\"Most frequent pair:\", most_frequent_pair, \"with count:\", merge_tables[most_frequent_pair])\n",
    "\n",
    "# update the frequency table by merging the most frequent pair\n",
    "new_frequency_table = {}\n",
    "for word, count in frequency_table.items():\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and word[i:i+2] == most_frequent_pair:\n",
    "            new_word.append(''.join(most_frequent_pair))\n",
    "            i += 2\n",
    "        else:\n",
    "            new_word.append(word[i])\n",
    "            i += 1\n",
    "    new_frequency_table[tuple(new_word)] = count\n",
    "\n",
    "\n",
    "new_frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd21ad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('l', 'o'): 7,\n",
       " ('o', 'w'): 7,\n",
       " ('w', 'e'): 2,\n",
       " ('e', 'r'): 2,\n",
       " ('w', 'i'): 3,\n",
       " ('i', 'd'): 3,\n",
       " ('d', 'es'): 3,\n",
       " ('es', 't'): 9,\n",
       " ('n', 'e'): 6,\n",
       " ('e', 'w'): 6,\n",
       " ('w', 'es'): 6}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  count the frequency of all adjacent character pairs\n",
    "merge_tables = {}\n",
    "for word, count in new_frequency_table.items():\n",
    "    \n",
    "     for i in range(len(word)-1):\n",
    "      \n",
    "          char_pair = word[i:i+2]\n",
    "          if char_pair not in merge_tables:\n",
    "                merge_tables[char_pair] = count\n",
    "          else:\n",
    "                merge_tables[char_pair] += count\n",
    "\n",
    "merge_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "265469dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('es', 't') with count: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('l', 'o', 'w'): 5,\n",
       " ('l', 'o', 'w', 'e', 'r'): 2,\n",
       " ('w', 'i', 'd', 'est'): 3,\n",
       " ('n', 'e', 'w', 'est'): 6}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the most frequent pair\n",
    "most_frequent_pair = max(merge_tables, key=merge_tables.get)\n",
    "print(\"Most frequent pair:\", most_frequent_pair, \"with count:\", merge_tables[most_frequent_pair])\n",
    "\n",
    "# update the frequency table by merging the most frequent pair\n",
    "frequency_table = {}\n",
    "for word, count in new_frequency_table.items():\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and word[i:i+2] == most_frequent_pair:\n",
    "            new_word.append(''.join(most_frequent_pair))\n",
    "            i += 2\n",
    "        else:\n",
    "            new_word.append(word[i])\n",
    "            i += 1\n",
    "    frequency_table[tuple(new_word)] = count\n",
    "\n",
    "\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1010867",
   "metadata": {},
   "source": [
    "Â∞ÜmergeËøô‰∏™ËøáÁ®ãÂÜôÊàêloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9691e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(merge_counts):\n",
    "    current_count = 1\n",
    "    while current_count <= merge_counts:\n",
    "        print(\"\\nMerge iteration:\", current_count)\n",
    "        #  count the frequency of all adjacent character pairs\n",
    "        merge_tables = {}\n",
    "        for word, count in frequency_table.items():\n",
    "            \n",
    "             for i in range(len(word)-1):\n",
    "              \n",
    "                  char_pair = word[i:i+2]\n",
    "                  if char_pair not in merge_tables:\n",
    "                        merge_tables[char_pair] = count\n",
    "                  else:\n",
    "                        merge_tables[char_pair] += count\n",
    "\n",
    "        # merge the most frequent pair\n",
    "        most_frequent_pair = max(merge_tables, key=merge_tables.get)\n",
    "        print(\"Most frequent pair:\", most_frequent_pair, \"with count:\", merge_tables[most_frequent_pair])\n",
    "\n",
    "        # update the frequency table by merging the most frequent pair\n",
    "        new_frequency_table = {}\n",
    "        for word, count in frequency_table.items():\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                if i < len(word) - 1 and word[i:i+2] == most_frequent_pair:\n",
    "                    new_word.append(''.join(most_frequent_pair))\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_frequency_table[tuple(new_word)] = count\n",
    "\n",
    "        frequency_table.clear()\n",
    "        frequency_table.update(new_frequency_table)\n",
    "        current_count += 1 \n",
    "\n",
    "    return frequency_table, merge_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67e683e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merge iteration: 1\n",
      "Most frequent pair: ('lo', 'w') with count: 7\n",
      "\n",
      "Merge iteration: 2\n",
      "Most frequent pair: ('n', 'e') with count: 6\n",
      "\n",
      "Merge iteration: 3\n",
      "Most frequent pair: ('ne', 'w') with count: 6\n",
      "\n",
      "Merge iteration: 4\n",
      "Most frequent pair: ('new', 'est') with count: 6\n",
      "\n",
      "Merge iteration: 5\n",
      "Most frequent pair: ('w', 'i') with count: 3\n"
     ]
    }
   ],
   "source": [
    "frequency_table, merge_tables = merge(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6e3152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('low', 'e'): 2, ('e', 'r'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a26b500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('low',): 5, ('low', 'e', 'r'): 2, ('wi', 'd', 'est'): 3, ('newest',): 6}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442e7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b11fadff",
   "metadata": {},
   "source": [
    "# training valid text result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6f81c",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "Performance Profile (sorted by cumulative time - shows call chains)\n",
    "================================================================================\n",
    "         128736260 function calls (128735955 primitive calls) in 630.064 seconds\n",
    "\n",
    "   Ordered by: cumulative time\n",
    "   List reduced from 511 to 20 due to restriction <20>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.104    0.104  630.064  630.064 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:233(bpe_tokenizer)\n",
    "        1  527.712  527.712  629.170  629.170 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:51(merge)\n",
    "127764200/127764160   99.081    0.000   99.081    0.000 {built-in method builtins.len}\n",
    "   297940    1.171    0.000    1.171    0.000 {method 'append' of 'list' objects}\n",
    "   194278    0.787    0.000    0.787    0.000 {built-in method _heapq.heappop}\n",
    "        1    0.004    0.004    0.747    0.747 /root/projects/assignment1-basics/cs336_basics/pretokenization_example.py:42(wrapper)\n",
    "        1    0.000    0.000    0.742    0.742 /root/projects/assignment1-basics/cs336_basics/pretokenization_example.py:180(process_parallel)\n",
    "        1    0.000    0.000    0.695    0.695 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:738(__exit__)\n",
    "        1    0.000    0.000    0.668    0.668 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:654(terminate)\n",
    "       21    0.000    0.000    0.654    0.031 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/util.py:272(__call__)\n",
    "        1    0.000    0.000    0.654    0.654 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:680(_terminate_pool)\n",
    "        1    0.000    0.000    0.653    0.653 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:671(_help_stuff_finish)\n",
    "        1    0.002    0.002    0.653    0.653 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
    "       40    0.000    0.000    0.651    0.016 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:202(send)\n",
    "      3/1    0.000    0.000    0.651    0.651 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/threading.py:1000(_bootstrap)\n",
    "      3/1    0.000    0.000    0.651    0.651 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/threading.py:1027(_bootstrap_inner)\n",
    "      3/1    0.000    0.000    0.650    0.650 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/threading.py:983(run)\n",
    "        1    0.000    0.000    0.650    0.650 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:527(_handle_tasks)\n",
    "       45    0.000    0.000    0.650    0.014 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:406(_send_bytes)\n",
    "       45    0.000    0.000    0.650    0.014 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:381(_send)\n",
    "\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Performance Profile (sorted by internal time - shows most time-consuming functions)\n",
    "================================================================================\n",
    "         128736260 function calls (128735955 primitive calls) in 630.064 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "   List reduced from 511 to 20 due to restriction <20>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1  527.712  527.712  629.170  629.170 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:51(merge)\n",
    "127764200/127764160   99.081    0.000   99.081    0.000 {built-in method builtins.len}\n",
    "   297940    1.171    0.000    1.171    0.000 {method 'append' of 'list' objects}\n",
    "   194278    0.787    0.000    0.787    0.000 {built-in method _heapq.heappop}\n",
    "    46/42    0.556    0.012    0.557    0.013 {built-in method posix.read}\n",
    "   217352    0.382    0.000    0.382    0.000 {built-in method _heapq.heappush}\n",
    "        1    0.104    0.104  630.064  630.064 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:233(bpe_tokenizer)\n",
    "       23    0.054    0.002    0.054    0.002 {built-in method _pickle.loads}\n",
    "       21    0.039    0.002    0.047    0.002 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/collections/__init__.py:673(update)\n",
    "     9772    0.032    0.000    0.032    0.000 {method 'items' of 'dict' objects}\n",
    "   103955    0.028    0.000    0.028    0.000 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:253(<genexpr>)\n",
    "    13113    0.015    0.000    0.015    0.000 {method 'encode' of 'str' objects}\n",
    "      159    0.012    0.000    0.550    0.003 {method 'poll' of 'select.poll' objects}\n",
    "    92860    0.008    0.000    0.008    0.000 {method 'get' of 'dict' objects}\n",
    "      104    0.007    0.000    0.007    0.000 {built-in method builtins.print}\n",
    "       18    0.005    0.000    0.005    0.000 {built-in method marshal.loads}\n",
    "        1    0.004    0.004    0.747    0.747 /root/projects/assignment1-basics/cs336_basics/pretokenization_example.py:42(wrapper)\n",
    "       20    0.004    0.000    0.004    0.000 {built-in method posix.fork}\n",
    "     1797    0.004    0.000    0.012    0.000 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/selectors.py:340(register)\n",
    "     1797    0.003    0.000    0.007    0.000 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/selectors.py:238(register)\n",
    "\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Training Summary\n",
    "================================================================================\n",
    "Time taken: 10 minute(s), 30.08 seconds (630.08 seconds total)\n",
    "Memory usage: 4.80 MB (peak: 18.83 MB)\n",
    "================================================================================\n",
    "\n",
    "Saved vocab to: /root/projects/assignment1-basics/data/tinystories-valid_vocab.json\n",
    "Saved merges to: /root/projects/assignment1-basics/data/tinystories-valid_merges.txt\n",
    "\n",
    "================================================================================\n",
    "Longest Token Analysis\n",
    "================================================================================\n",
    "Longest token (serialized string): 'ƒ†accomplishment'\n",
    "Token length: 15 characters (in serialized form)\n",
    "Token ID: 7338\n",
    "Token bytes: b' accomplishment'\n",
    "Token bytes length: 15 bytes\n",
    "Decoded as UTF-8: ' accomplishment'\n",
    "Does it make sense? Yes - contains readable text\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5ff70",
   "metadata": {},
   "source": [
    "# train train-text\n",
    "\n",
    "Âπ∂Ë°åÂ§ÑÁêÜ ËÄóÊó∂: 65.74 Áßí\n",
    "Pretokenization complete. Unique tokens: 59933\n",
    "Converting tokens to byte sequences...\n",
    "Conversion complete. Unique byte sequences: 59933\n",
    "Initializing merge_tables with 59933 unique tokens...\n",
    "Starting BPE merging: 9743 merges needed...\n",
    "Progress: 100/9743 merges completed (1.0%)\n",
    "Progress: 200/9743 merges completed (2.1%)\n",
    "Progress: 300/9743 merges completed (3.1%)\n",
    "Progress: 400/9743 merges completed (4.1%)\n",
    "Progress: 500/9743 merges completed (5.1%)\n",
    "Progress: 600/9743 merges completed (6.2%)\n",
    "Progress: 700/9743 merges completed (7.2%)\n",
    "Progress: 800/9743 merges completed (8.2%)\n",
    "Progress: 900/9743 merges completed (9.2%)\n",
    "Progress: 1000/9743 merges completed (10.3%)\n",
    "Progress: 1100/9743 merges completed (11.3%)\n",
    "Progress: 1200/9743 merges completed (12.3%)\n",
    "Progress: 1300/9743 merges completed (13.3%)\n",
    "Progress: 1400/9743 merges completed (14.4%)\n",
    "Progress: 1500/9743 merges completed (15.4%)\n",
    "Progress: 1600/9743 merges completed (16.4%)\n",
    "Progress: 1700/9743 merges completed (17.4%)\n",
    "Progress: 1800/9743 merges completed (18.5%)\n",
    "Progress: 1900/9743 merges completed (19.5%)\n",
    "Progress: 2000/9743 merges completed (20.5%)\n",
    "Progress: 2100/9743 merges completed (21.6%)\n",
    "Progress: 2200/9743 merges completed (22.6%)\n",
    "Progress: 2300/9743 merges completed (23.6%)\n",
    "Progress: 2400/9743 merges completed (24.6%)\n",
    "Progress: 2500/9743 merges completed (25.7%)\n",
    "Progress: 2600/9743 merges completed (26.7%)\n",
    "Progress: 2700/9743 merges completed (27.7%)\n",
    "Progress: 2800/9743 merges completed (28.7%)\n",
    "Progress: 2900/9743 merges completed (29.8%)\n",
    "Progress: 3000/9743 merges completed (30.8%)\n",
    "Progress: 3100/9743 merges completed (31.8%)\n",
    "Progress: 3200/9743 merges completed (32.8%)\n",
    "Progress: 3300/9743 merges completed (33.9%)\n",
    "Progress: 3400/9743 merges completed (34.9%)\n",
    "Progress: 3500/9743 merges completed (35.9%)\n",
    "Progress: 3600/9743 merges completed (36.9%)\n",
    "Progress: 3700/9743 merges completed (38.0%)\n",
    "Progress: 3800/9743 merges completed (39.0%)\n",
    "Progress: 3900/9743 merges completed (40.0%)\n",
    "Progress: 4000/9743 merges completed (41.1%)\n",
    "Progress: 4100/9743 merges completed (42.1%)\n",
    "Progress: 4200/9743 merges completed (43.1%)\n",
    "Progress: 4300/9743 merges completed (44.1%)\n",
    "Progress: 4400/9743 merges completed (45.2%)\n",
    "Progress: 4500/9743 merges completed (46.2%)\n",
    "Progress: 4600/9743 merges completed (47.2%)\n",
    "Progress: 4700/9743 merges completed (48.2%)\n",
    "Progress: 4800/9743 merges completed (49.3%)\n",
    "Progress: 4900/9743 merges completed (50.3%)\n",
    "Progress: 5000/9743 merges completed (51.3%)\n",
    "Progress: 5100/9743 merges completed (52.3%)\n",
    "Progress: 5200/9743 merges completed (53.4%)\n",
    "Progress: 5300/9743 merges completed (54.4%)\n",
    "Progress: 5400/9743 merges completed (55.4%)\n",
    "Progress: 5500/9743 merges completed (56.5%)\n",
    "Progress: 5600/9743 merges completed (57.5%)\n",
    "Progress: 5700/9743 merges completed (58.5%)\n",
    "Progress: 5800/9743 merges completed (59.5%)\n",
    "Progress: 5900/9743 merges completed (60.6%)\n",
    "Progress: 6000/9743 merges completed (61.6%)\n",
    "Progress: 6100/9743 merges completed (62.6%)\n",
    "Progress: 6200/9743 merges completed (63.6%)\n",
    "Progress: 6300/9743 merges completed (64.7%)\n",
    "Progress: 6400/9743 merges completed (65.7%)\n",
    "Progress: 6500/9743 merges completed (66.7%)\n",
    "Progress: 6600/9743 merges completed (67.7%)\n",
    "Progress: 6700/9743 merges completed (68.8%)\n",
    "Progress: 6800/9743 merges completed (69.8%)\n",
    "Progress: 6900/9743 merges completed (70.8%)\n",
    "Progress: 7000/9743 merges completed (71.8%)\n",
    "Progress: 7100/9743 merges completed (72.9%)\n",
    "Progress: 7200/9743 merges completed (73.9%)\n",
    "Progress: 7300/9743 merges completed (74.9%)\n",
    "Progress: 7400/9743 merges completed (76.0%)\n",
    "Progress: 7500/9743 merges completed (77.0%)\n",
    "Progress: 7600/9743 merges completed (78.0%)\n",
    "Progress: 7700/9743 merges completed (79.0%)\n",
    "Progress: 7800/9743 merges completed (80.1%)\n",
    "Progress: 7900/9743 merges completed (81.1%)\n",
    "Progress: 8000/9743 merges completed (82.1%)\n",
    "Progress: 8100/9743 merges completed (83.1%)\n",
    "Progress: 8200/9743 merges completed (84.2%)\n",
    "Progress: 8300/9743 merges completed (85.2%)\n",
    "Progress: 8400/9743 merges completed (86.2%)\n",
    "Progress: 8500/9743 merges completed (87.2%)\n",
    "Progress: 8600/9743 merges completed (88.3%)\n",
    "Progress: 8700/9743 merges completed (89.3%)\n",
    "Progress: 8800/9743 merges completed (90.3%)\n",
    "Progress: 8900/9743 merges completed (91.3%)\n",
    "Progress: 9000/9743 merges completed (92.4%)\n",
    "Progress: 9100/9743 merges completed (93.4%)\n",
    "Progress: 9200/9743 merges completed (94.4%)\n",
    "Progress: 9300/9743 merges completed (95.5%)\n",
    "Progress: 9400/9743 merges completed (96.5%)\n",
    "Progress: 9500/9743 merges completed (97.5%)\n",
    "Progress: 9600/9743 merges completed (98.5%)\n",
    "Progress: 9700/9743 merges completed (99.6%)\n",
    "Progress: 9743/9743 merges completed (100.0%)\n",
    "\n",
    "================================================================================\n",
    "Performance Profile (sorted by cumulative time - shows call chains)\n",
    "================================================================================\n",
    "         588197441 function calls (588197136 primitive calls) in 3624.529 seconds\n",
    "\n",
    "   Ordered by: cumulative time\n",
    "   List reduced from 511 to 20 due to restriction <20>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.929    0.929 3624.528 3624.528 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:233(bpe_tokenizer)\n",
    "        1 3091.468 3091.468 3557.664 3557.664 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:51(merge)\n",
    "583997919/583997879  455.537    0.000  455.537    0.000 {built-in method builtins.len}\n",
    "        1    0.034    0.034   65.737   65.737 /root/projects/assignment1-basics/cs336_basics/pretokenization_example.py:42(wrapper)\n",
    "        1    0.000    0.000   65.703   65.703 /root/projects/assignment1-basics/cs336_basics/pretokenization_example.py:180(process_parallel)\n",
    "        1    0.000    0.000   65.431   65.431 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:738(__exit__)\n",
    "        1    0.000    0.000   65.401   65.401 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:654(terminate)\n",
    "       21    0.000    0.000   65.381    3.113 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/util.py:272(__call__)\n",
    "        1    0.000    0.000   65.380   65.380 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:680(_terminate_pool)\n",
    "        1    0.000    0.000   65.342   65.342 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:671(_help_stuff_finish)\n",
    "        1    0.004    0.004   65.342   65.342 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
    "       40    0.000    0.000   65.338    1.633 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:202(send)\n",
    "      3/1    0.000    0.000   65.337   65.337 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/threading.py:1000(_bootstrap)\n",
    "      3/1    0.000    0.000   65.337   65.337 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/threading.py:1027(_bootstrap_inner)\n",
    "      3/1    0.000    0.000   65.337   65.337 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/threading.py:983(run)\n",
    "        1    0.000    0.000   65.337   65.337 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:527(_handle_tasks)\n",
    "       45    0.000    0.000   65.337    1.452 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:406(_send_bytes)\n",
    "       45    0.000    0.000   65.337    1.452 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/connection.py:381(_send)\n",
    "       45    0.000    0.000   65.337    1.452 {built-in method posix.write}\n",
    "        1    0.000    0.000   65.336   65.336 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/multiprocessing/pool.py:573(_handle_results)\n",
    "\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Performance Profile (sorted by internal time - shows most time-consuming functions)\n",
    "================================================================================\n",
    "         588197441 function calls (588197136 primitive calls) in 3624.529 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "   List reduced from 511 to 20 due to restriction <20>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1 3091.468 3091.468 3557.664 3557.664 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:51(merge)\n",
    "583997919/583997879  455.537    0.000  455.537    0.000 {built-in method builtins.len}\n",
    "  126/122   58.632    0.465   58.633    0.481 {built-in method posix.read}\n",
    "      301    6.303    0.021    6.303    0.021 {method 'poll' of 'select.poll' objects}\n",
    "  1369385    5.345    0.000    5.345    0.000 {method 'append' of 'list' objects}\n",
    "   746269    3.476    0.000    3.476    0.000 {built-in method _heapq.heappop}\n",
    "  1022782    1.801    0.000    1.801    0.000 {built-in method _heapq.heappush}\n",
    "        1    0.929    0.929 3624.528 3624.528 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:233(bpe_tokenizer)\n",
    "       23    0.341    0.015    0.341    0.015 {built-in method _pickle.loads}\n",
    "       21    0.204    0.010    0.267    0.013 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/collections/__init__.py:673(update)\n",
    "   495038    0.131    0.000    0.131    0.000 /root/projects/assignment1-basics/cs336_basics/train_bpe.py:253(<genexpr>)\n",
    "    59935    0.066    0.000    0.066    0.000 {method 'encode' of 'str' objects}\n",
    "   424682    0.062    0.000    0.062    0.000 {method 'get' of 'dict' objects}\n",
    "     3213    0.047    0.000    0.391    0.000 {built-in method posix.waitpid}\n",
    "        1    0.034    0.034   65.737   65.737 /root/projects/assignment1-basics/cs336_basics/pretokenization_example.py:42(wrapper)\n",
    "     9772    0.033    0.000    0.033    0.000 {method 'items' of 'dict' objects}\n",
    "     3430    0.008    0.000    0.025    0.000 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/selectors.py:340(register)\n",
    "      104    0.008    0.000    0.008    0.000 {built-in method builtins.print}\n",
    "       37    0.007    0.000    0.007    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
    "     3430    0.007    0.000    0.014    0.000 /root/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/selectors.py:238(register)\n",
    "\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Training Summary\n",
    "================================================================================\n",
    "Time taken: 1 hour(s), 0 minute(s), 24.61 seconds (3624.61 seconds total)\n",
    "Memory usage: 5.40 MB (peak: 83.62 MB)\n",
    "================================================================================\n",
    "\n",
    "Saved vocab to: /root/projects/assignment1-basics/data/tinystories-train_vocab.json\n",
    "Saved merges to: /root/projects/assignment1-basics/data/tinystories-train_merges.txt\n",
    "\n",
    "================================================================================\n",
    "Longest Token Analysis\n",
    "================================================================================\n",
    "Longest token (serialized string): 'ƒ†accomplishment'\n",
    "Token length: 15 characters (in serialized form)\n",
    "Token ID: 7179\n",
    "Token bytes: b' accomplishment'\n",
    "Token bytes length: 15 bytes\n",
    "Decoded as UTF-8: ' accomplishment'\n",
    "Does it make sense? Yes - contains readable text\n",
    "================================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4828d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_finetune3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
